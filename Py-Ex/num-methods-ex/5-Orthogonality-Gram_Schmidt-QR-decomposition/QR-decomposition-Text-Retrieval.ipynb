{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QR factorization for text retrieval\n",
    "In this notebook, we would like to compare the cosine similarity with the QR factorization in the context of text retrieval. So, given the term-document matrix A and the two query vectors defined in the following code, we compute the cosine similarity between the query vectors and the matrix A to find which documents are meaningful for the given query. Then, we define an additional query and analyze the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as spl\n",
    "import sklearn.feature_extraction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:32.221248600Z",
     "start_time": "2024-02-21T20:35:19.432046600Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text retrieval with cosine similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the term-by-document matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:32.223248500Z",
     "start_time": "2024-02-21T20:35:32.143304900Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "vectorizer = sklearn.feature_extraction.text.CountVectorizer(min_df=1)\n",
    "documents = [\n",
    "'The rank of a matrix is the maximum number of linearly independent columns.',\n",
    "'The column space of a matrix A is called range of A.',\n",
    "'The two norm of a vector is called Euclidean norm.',\n",
    "'The function norm satisfies the triangular inequality.',\n",
    "'The inverse of an orthogonal matrix is its transpose.',\n",
    "'The product of an orthogonal matrix and its traspose is the identity matrix.',\n",
    "'The matrix vector product is not commutative',\n",
    "'The rank of a matrix is the maximum number of  linearly independent rows.',\n",
    "'A set of orthogonal vectors is a linearly independent set.',\n",
    "'The columns of an orthogonal matrix are a set of orthogonal vectors.',\n",
    "'A normed vectorial space is a space with an inner product norm.',\n",
    "'An inner product space is a vectorial space with an inner product',\n",
    "'A norm can be induced by an inner product.']"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized.vocabulary_: {'the': 36, 'rank': 31, 'of': 27, 'matrix': 21, 'is': 18, 'maximum': 22, 'number': 26, 'linearly': 20, 'independent': 13, 'columns': 8, 'column': 7, 'space': 35, 'called': 5, 'range': 30, 'two': 40, 'norm': 23, 'vector': 41, 'euclidean': 10, 'function': 11, 'satisfies': 33, 'triangular': 39, 'inequality': 15, 'inverse': 17, 'an': 0, 'orthogonal': 28, 'its': 19, 'transpose': 37, 'product': 29, 'and': 1, 'traspose': 38, 'identity': 12, 'not': 25, 'commutative': 9, 'rows': 32, 'set': 34, 'vectors': 43, 'are': 2, 'normed': 24, 'vectorial': 42, 'with': 44, 'inner': 16, 'can': 6, 'be': 3, 'induced': 14, 'by': 4}\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(documents).toarray()\n",
    "print('vectorized.vocabulary_: {0}'.format(vectorizer.vocabulary_))\n",
    "A=X.T # we compute the transpose and work with this to have on the rows the terms, and on the columns the documents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:32.465950Z",
     "start_time": "2024-02-21T20:35:32.144304500Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:32.564892700Z",
     "start_time": "2024-02-21T20:35:32.389034300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the term-by-document matrix is (45,13)\n",
      "There are 45 terms and 13 documents.\n"
     ]
    }
   ],
   "source": [
    "(m,n)=A.shape\n",
    "print(f'The shape of the term-by-document matrix is ({m},{n})')\n",
    "print(f'There are {m} terms and {n} documents.')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we want to compute the norm of each column of our matrix A, and then we want to divide each column by its norm, to have at the end each column with norm = 1. In this way, we can simply the computation of the cosine since we don't need to divide by the norm of each column of the matrix (because it is already 1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eu=np.array(np.zeros(n))\n",
    "for i in range(n):\n",
    "    eu[i] = np.linalg.norm(A[:,i],2)\n",
    "As = np.dot(A,np.diag(1/eu))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:32.797762200Z",
     "start_time": "2024-02-21T20:35:32.537916100Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can define the first query vector."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:32.968155100Z",
     "start_time": "2024-02-21T20:35:32.798759900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query-vector: \n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]]\n",
      "The shape of the query-vector: (1, 45)\n",
      "The shape of the query-vector after transposition: (45, 1)\n"
     ]
    }
   ],
   "source": [
    "query1text = ['rank of a matrix?']\n",
    "query1 = vectorizer.transform(query1text).toarray()\n",
    "print('query-vector: \\n{0}'.format(query1))\n",
    "print('The shape of the query-vector:',query1.shape)\n",
    "query1 = query1.T\n",
    "print('The shape of the query-vector after transposition:',query1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we would like to compute the cosine of the angle between the query one and each column of the term-by-document matrix. In general, \n",
    "\n",
    "$cos(\\theta) = \\frac{x^Ty}{\\|x\\|\\|y\\|}$. If we have a term-by-document matrix, $cos(\\theta_j) = \\frac{A_{*j}q}{\\|A_{*j}\\|\\|q\\|}$. We can simply compute the dot product between the matrix and the query to compute one-shot all the cosine. <br>\n",
    "<b>NB</b>: in this case, we don't divide by the norm of the matrix because we have already divided each column by its own norm and so the norm of the matrix is equal one.<br> At the end, fixed a threshold equal to 0.5, we can retrieve the document releated to the defined query. Usually, less than 0.5 is not good, and so we don't take anything."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:33.218399400Z",
     "start_time": "2024-02-21T20:35:32.970154300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity releated to the query1 are:\n",
      " [[0.57735027 0.52223297 0.17407766 0.         0.38490018 0.42008403\n",
      "  0.21821789 0.57735027 0.18257419 0.4472136  0.         0.\n",
      "  0.        ]]\n",
      "Query1 is:  ['rank of a matrix?']\n",
      "Founded documents are:\n",
      " ['The rank of a matrix is the maximum number of linearly independent columns.', 'The rank of a matrix is the maximum number of  linearly independent rows.']\n"
     ]
    }
   ],
   "source": [
    "cos_query1 = np.dot(query1.T,As)/np.linalg.norm(query1,2)\n",
    "print('The cosine similarity releated to the query1 are:\\n', cos_query1)\n",
    "print('Query1 is: ', query1text)\n",
    "print('Founded documents are:\\n',\n",
    "      [documents[i] for i in np.where(cos_query1 == np.max(cos_query1))[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we define a second query vector."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:33.407291600Z",
     "start_time": "2024-02-21T20:35:33.220399200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query-vector: \n",
      "[[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]]\n",
      "The shape of the query-vector: (1, 45)\n",
      "The shape of the query-vector after transposition: (45, 1)\n"
     ]
    }
   ],
   "source": [
    "query2text = ['euclidean norm']\n",
    "query2 = vectorizer.transform(query2text).toarray()\n",
    "print('query-vector: \\n{0}'.format(query2))\n",
    "print('The shape of the query-vector:',query2.shape)\n",
    "query2 = query2.T\n",
    "print('The shape of the query-vector after transposition:',query2.shape)\n",
    "# scaled query vector\n",
    "#query2=query2/np.linalg.norm(query2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:33.622354800Z",
     "start_time": "2024-02-21T20:35:33.408290800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity releated to the query2 are:\n",
      " [[0.         0.         0.63960215 0.23570226 0.         0.\n",
      "  0.         0.         0.         0.         0.20412415 0.\n",
      "  0.25      ]]\n",
      "Query2 is:  ['euclidean norm']\n",
      "Founded documents are:\n",
      " ['The two norm of a vector is called Euclidean norm.']\n"
     ]
    }
   ],
   "source": [
    "cos_query2 = np.dot(query2.T,As)/np.linalg.norm(query2,2)\n",
    "print('The cosine similarity releated to the query2 are:\\n', cos_query2)\n",
    "print('Query2 is: ', query2text)\n",
    "print('Founded documents are:\\n',\n",
    "      [documents[i] for i in np.where(cos_query2 == np.max(cos_query2))[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text retrieval using QR factorization with pivoting\n",
    "Compute the QR factorization, with pivoting true, of the scaled term-document matrix and use the QR factors to compute the cosine similarity. Compute an approximation of the term-document matrix by using nc columns of Q and nc rows of R (as in the first exercise). Use this approximation to compute again the cosine similarity and comment the results."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Computing the QR with pivoting, we can check that all the diagonal elements of the matrix R are sorted. In general, it is necessary to use column pivoting during the QR factorization to ensure that the zeros appear at the bottom of the matrix AP = QR."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:33.858263700Z",
     "start_time": "2024-02-21T20:35:33.626353300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -1.         -0.93541435  0.90965028 -0.90475592 -0.89621574\n",
      "  0.8327188  -0.82051483  0.70238715 -0.65504204 -0.56200771 -0.41935821\n",
      "  0.32819427]\n"
     ]
    }
   ],
   "source": [
    "[Q,R,P]=spl.qr(As,pivoting=True)\n",
    "print(np.diag(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we put r = 10, and we take from the matrix Q just the first r columns, and from the matrix R the first r rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "r = 8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:33.975324900Z",
     "start_time": "2024-02-21T20:35:33.859262700Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, we can compute the matrix $Q_A = Q_{*,0..r}$ which defines the basis for the column spaceâ€”R(A). The columns of QAO are a basis for the orthogonal complement of the column space of AP and so of the column space of A. We do the same for $R_A = Q_{0..r,*}$.\n",
    "Column pivoting provides important numerical advantages without changing the database, as permuting the columns of A results only in a reordering of the document vectors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:34.177718300Z",
     "start_time": "2024-02-21T20:35:33.976326700Z"
    }
   },
   "outputs": [],
   "source": [
    "QA=np.copy(Q[:,0:r])\n",
    "QAO=np.copy(Q[:,r:m])\n",
    "RA=np.copy(R[0:r,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:34.395960400Z",
     "start_time": "2024-02-21T20:35:34.179713700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costeta between matrix and query 1:\n",
      " [[0.57735027 0.         0.         0.         0.18257419 0.21821789\n",
      "  0.17407766 0.38490018 0.52223297 0.4472136  0.42008403 0.\n",
      "  0.57735027]]\n",
      "costeta between the approximated matrix and query 1:\n",
      " [[ 0.57735027  0.         -0.         -0.          0.18257419  0.21821789\n",
      "   0.17407766  0.38490018  0.36863684  0.31610915  0.35157499  0.02968657\n",
      "   0.53878653]]\n"
     ]
    }
   ],
   "source": [
    "costet=np.dot(As[:,P].T,query1)/np.linalg.norm(query1,2)\n",
    "print('costeta between matrix and query 1:\\n',np.transpose(costet))\n",
    "\n",
    "costet=np.dot(RA.T,np.dot(QA.T,query1))/np.linalg.norm(query1,2)\n",
    "print('costeta between the approximated matrix and query 1:\\n',np.transpose(costet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-21T20:35:34.649278800Z",
     "start_time": "2024-02-21T20:35:34.397959900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos query 1\n",
      "[[ 0.57735027  0.         -0.         -0.          0.18257419  0.21821789\n",
      "   0.17407766  0.38490018  0.30166037  0.42352088  0.30319247  0.03277066\n",
      "   0.50950867]]\n",
      "cos query 2\n",
      "[[ 0.          0.25        0.23570226  0.20412415  0.          0.\n",
      "   0.63960215  0.          0.11278966 -0.00045259 -0.00840464  0.05663592\n",
      "   0.0103117 ]]\n"
     ]
    }
   ],
   "source": [
    "RAs=np.copy(R) \n",
    "RAs[r:m,:]=0\n",
    "E = np.dot(Q,RAs)-np.dot(Q,R)\n",
    "AE = As+E\n",
    "AEeu=np.array(np.zeros((1,n)))\n",
    "for i in range(n):\n",
    "    AEeu[0,i] = np.linalg.norm(AE[:,i],2)\n",
    "\n",
    "QAs=np.copy(Q[:,0:r])\n",
    "# QAs basis for the column space of a subsapce of the columns space A\n",
    "RAs=RAs[0:r,:]\n",
    "\n",
    "#(QAs,RAs)=np.linalg.qr(AE)\n",
    "\n",
    "costeta1=np.dot(RAs.T,np.dot(QAs.T,query1))/(AEeu.T * np.linalg.norm(query1, 2))\n",
    "print('cos query 1')\n",
    "print(np.transpose(costeta1))\n",
    "\n",
    "print('cos query 2')\n",
    "costeta2=np.dot(RAs.T,np.dot(QAs.T,query2))/(AEeu.T * np.linalg.norm(query2, 2))\n",
    "print(np.transpose(costeta2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
